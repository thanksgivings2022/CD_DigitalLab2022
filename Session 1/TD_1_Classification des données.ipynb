{"cells":[{"cell_type":"markdown","metadata":{"lang":"fr","id":"6flOW34yaco3"},"source":["_La base des TDs pour le cours \"Classification des données\" a été prise du cours en ligne \"Open Machine Learning Course\" (https://mlcourse.ai/, __auteur Yury Kashnitsky__)_ "]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"WUrdLQK0aco_"},"source":["# <center> TD 1. Analyse exploratoire et analyse visuelle de données avec la librairie Pandas et Seaborn"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"BHW6i7VtacpA"},"source":["## 1. Mise en pratique des principales méthodes de Pandas\n","\n","**[Pandas](http://pandas.pydata.org)** est une bibliothèque Python qui fournit des moyens étendus pour l’analyse de données. Les Data scientistes travaillent souvent avec des données stockées dans des formats sous forme de table de données telles que `.csv`,` .tsv` ou `.xlsx`. Pandas est très pratique pour charger, traiter et analyser ces données tabulaires à l’aide de requêtes quasi-similaires aux requêtes de type SQL. En complément de `Matplotlib` et` Seaborn`, `Pandas` offre un large éventail d'opportunités d'analyse visuelle des données tabulaires.\n","\n","Les pricipales structures de données dans `Pandas` sont implémentées avec les classes **Series** et **DataFrame**. Le premier est un tableau unidimensionnel indexé d'un type de données fixe. Le second est une structure de données bi-dimensionnelle - une table - dans laquelle chaque colonne contient des données du même type. Vous pouvez la voir comme un dictionnaire de plusieurs `Series`. Les `DataFrames` sont parfaits pour représenter des données réelles : les lignes correspondent aux instances (exemples, observations, individus etc.) et les colonnes correspondent aux caractéristiques de ces instances (variables).\n","\n","Vous pouvez trouver tous les commandes utiles de Pandas dans le fichier \"Pandas Cheat Sheet\" (https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-09-15T20:51:25.725973Z","start_time":"2019-09-15T20:51:18.418535Z"},"id":"pNniluwiacpD"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","pd.set_option(\"display.precision\", 2)\n","\n","# quelques imports pour mettre en place le cadre du graphique \n","import matplotlib.pyplot as plt\n","\n","# !pip install seaborn  #(pour installer la librairie seaborn via le notebook)\n","import seaborn as sns\n","\n","# import de paramètres pour améliorer le rendu visuel\n","sns.set()\n","# Les graphiques au format Retina sont plus nets et plus lisibles\n","%config InlineBackend.figure_format = 'retina'"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"-mizgnJvacpF"},"source":["Nous allons tester les principales méthodes en analysant un jeu de données ou [dataset](https://bigml.com/user/francisco/gallery/dataset/5163ad540c0b5e5b22000383) sur le taux de désabonnement des clients d'opérateurs téléphoniques. Chargons les données (en utilisant la méthode `read_csv`), et jetons un coup d’œil aux 5 premières lignes en utilisant la méthode` head`:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-09-15T20:58:48.483494Z","start_time":"2019-09-15T20:58:47.885539Z"},"id":"o9gr4BS6acpF"},"outputs":[],"source":["url = \"https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/data/telecom_churn.csv\"\n","df = pd.read_csv(url)\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"GZADBu_-acpG"},"source":["Rappelez-vous que chaque ligne correspond à un client, à une **instance** et les colonnes sont les **caractéristiques** de cette instance."]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"GlB4_UDAacpH"},"source":["Examinons la dimensionnalité des données, les noms des caractéristiques et les types de caractéristiques."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQ3Skbo_acpI"},"outputs":[],"source":["print(df.info())"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"_4VAt3VmacpK"},"source":["`bool`,` int64`, `float64` et` object` sont les types de données de nos caractéristiques. Nous voyons qu'une caractéristique est logique (`bool`), 3 caractéristiques sont de type ` objet`, et 16 caractéristiques sont numériques. Avec cette même méthode, nous pouvons facilement voir s’il manque des valeurs. Ici, il n'y en a pas car chaque colonne contient 3333 observations.\n","\n","Nous pouvons **changer le type de colonne** avec la méthode `astype`. Appliquons cette méthode à la caractéristique `Churn` pour la convertir en` int64`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xsXBgv_vacpL"},"outputs":[],"source":["df['Churn'] = df['Churn'].astype('int64')"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"9a04dfJ7acpL"},"source":["La méthode `describe` affiche les caractéristiques statistiques de base de chaque caractéristique numérique (type ` int64` et `float64`): nombre de valeurs non manquantes, moyenne, écart-type, amplitude, médiane, (1er : 0,25) et (3ème : 0,75) quartiles."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2kx4GXwacpM"},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"Bcl6V4X2acpM"},"source":["Afin de voir les statistiques des caractéristiques non numériques, il faut indiquer explicitement ces types de données dans le paramètre `include`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FchzfckPacpN"},"outputs":[],"source":["df.describe(include=['object', 'bool'])"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"4tbbblTeacpN"},"source":["Pour les caractéristiques catégorielles (type `objet`) et booléennes (type` bool`), nous pouvons utiliser la méthode `value_counts`. Jetons un coup d'oeil à la distribution de `Churn` (la caractéristique cible pour cette base des données) :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nOyPmsBacpO"},"outputs":[],"source":["df['Churn'].value_counts()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"kZQAeCV6acpO"},"source":["2850 utilisateurs sur 3333 sont clients *fidèles*; leur valeur `Churn` est 0. Pour calculer les pourcentages, passez ` normalize = True` à la fonction `value_counts`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTY0y-Z3acpP"},"outputs":[],"source":["df['Churn'].value_counts(normalize=True)"]},{"cell_type":"markdown","metadata":{"id":"-efgVCDvacpP"},"source":["Ou avec la visualisation :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lXuuzooacpQ"},"outputs":[],"source":["df['Churn'].value_counts().plot(kind='bar', label='Churn')\n","plt.legend()\n","plt.title('Répartition de désabonnement de clients');"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"nLEz1dIIacpR"},"source":["### Tri\n","\n","Un `DataFrame` peut être trié selon la valeur de l’une des variables (colonnes). Par exemple, nous pouvons trier par *Total day charge*  \n","(utilisez `ascending = False` pour trier par ordre décroissant):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10slv-tfacpR"},"outputs":[],"source":["df.sort_values(by='Total day charge', ascending=False).head()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"RIBcD9GNacpS"},"source":["Nous pouvons également trier sur plusieurs colonnes:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5AhvI-dTacpS"},"outputs":[],"source":["df.sort_values(by=['Churn', 'Total day charge'], ascending=[True, False]).head()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"Q9wyFnI_acpS"},"source":["### Indexation et récupération de données\n","\n","Un `DataFrame` peut être indexé de différentes manières.\n","\n","Pour obtenir une seule colonne, vous pouvez saisir : `DataFrame['NomDeColonne'] `. Que nous utilisons pour répondre à une question à propos de cette colonne uniquement: **quelle est la proportion d'utilisateurs qui se sont désabonnés dans notre base de données?**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M3LEoT7racpT"},"outputs":[],"source":["df['Churn'].mean()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"XDlAS0DtacpT"},"source":["14,5% est en fait assez mauvais pour une entreprise; un tel taux de désabonnement peut entraîner la faillite de l'entreprise.\n","\n","**L'indexation booléenne** avec une colonne est également très pratique. La syntaxe est `df[P(df['Nom']]]`, où `P` est une condition logique vérifiée pour chaque élément de la colonne ` NomDeColonne`. Le résultat de cette indexation est le `DataFrame` composé uniquement de lignes satisfaisant la condition ` P` de la colonne `NomDeColonne`.\n","\n","Exemple d'utlisation pour répondre à la question:\n","\n","**Quelles sont les valeurs moyennes des caractéristiques numériques pour les utilisateurs désabonnés, c'est-à-dire qui ont un Churn égal à 1 ?**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-opDveGhacpU"},"outputs":[],"source":["df[df['Churn'] == 1].mean()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"7BKZfd-2acpU"},"source":["**Combien de temps (en moyenne) les utilisateurs désabonnés passent-ils au téléphone pendant la journée?**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6nUNjWtYacpU"},"outputs":[],"source":["df[df['Churn'] == 1]['Total day minutes'].mean()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"jF4FFI0KacpV"},"source":["**Quelle est la durée maximale des appels internationaux parmi les clients fidèles (`Churn == 0`) n'ayant pas de forfait international?**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"051S-KLRacpV"},"outputs":[],"source":["df[(df['Churn'] == 0) & (df['International plan'] == 'No')]['Total intl minutes'].max()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"F_fiPb0SacpV"},"source":["Les DataFrames peuvent être indexés par nom de colonne (étiquette) ou nom de ligne (index) ou par le numéro de série (indice) d'une ligne. La méthode `loc` est utilisée pour **l'indexation par nom**, tandis que` iloc() `est utilisée pour **l'indexation par numéro**.\n","\n","Dans le premier cas ci-dessous, nous *\"récupérons les valeurs des lignes d'index de 0 à 5 (inclus) et des colonnes étiquetées de  State à Area code (inclus)\"*.  \n","Dans le second cas, nous *\"récupérons les valeurs des cinq premières lignes des trois premières colonnes\"* (comme dans un slicing avec Python : la valeur maximale n'est pas incluse)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DH59ILxuacpW"},"outputs":[],"source":["df.loc[0:5, 'State':'Area code']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBdfSLR3acpW"},"outputs":[],"source":["df.iloc[0:5, 0:3]"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"h_nRHd7macpX"},"source":["Si nous avons besoin de la première ou de la dernière ligne du dataframe, nous pouvons utiliser la syntaxe : `df[:1]` ou `df[-1:]`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"slqtLLaNacpX"},"outputs":[],"source":["df[-1:]"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"ShuL9XnbacpY"},"source":["### Application de fonctions à des cellules, des colonnes et des lignes\n","\n","**Pour appliquer des fonctions à chaque colonne, utilisez `apply ()`:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7pM82SvacpY"},"outputs":[],"source":["df.apply(np.max) "]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"VJqvTj0PacpY"},"source":["La méthode `apply` peut également être utilisée pour appliquer une fonction à chaque ligne. Pour ce faire, spécifiez `axis = 1`. Les fonctions Lambda sont très pratiques dans de tels scénarios. Par exemple, si nous devons sélectionner tous les _state_ commençant par 'W', nous pouvons le faire comme suit:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dCjuLVqsacpZ"},"outputs":[],"source":["df[df['State'].apply(lambda state: state[0] == 'W')].head()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"wiUIyYe-acpZ"},"source":["La méthode `map` peut être utilisée pour **remplacer des valeurs dans une colonne** en transmettant un dictionnaire de la forme` {ancienne_valeur: nouvelle_valeur} `comme argument:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0vWp2Y-_acpa"},"outputs":[],"source":["d = {'No' : False, 'Yes' : True}\n","df['International plan'] = df['International plan'].map(d)\n","df.head()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"CxijjK-Uacpa"},"source":["Presque la même chose peut être faite avec la méthode `replace`.\n","\n","<details>\n","\n","<p>\n","Il y a une petite différence.  \n","La méthode `replace` ne fera rien avec des valeurs qui ne se trouvent pas dans le dictionnaire de mappage,  \n","alors que `map` les changera en `NaN`).  \n","<br>    \n","    \n","```python\n","a_series = pd.Series(['a', 'b', 'c'])\n","a_series.replace({'a': 1, 'b': 1}) # 1, 2, c\n","a_series.map({'a': 1, 'b': 2}) # 1, 2, NaN\n","```\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RkC1qIt-acpa"},"outputs":[],"source":["df = df.replace({'Voice mail plan': d})\n","df.head()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"NYV4YX5hacpb"},"source":["### Agrégation de données\n","\n","En général, le regroupement des données dans Pandas fonctionne comme suit :"]},{"cell_type":"markdown","metadata":{"id":"j4bSmWsdacpb"},"source":["\n","```python\n","df.groupby(by=grouping_columns)[columns_to_show].function()\n","```"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"ydTLVn9zacpb"},"source":["1. Premièrement, la méthode `groupby` divise les colonnes`grouping_columns` par leurs valeurs. Ils deviennent un nouvel index dans le dataframe qui en  résulte.\n","2. Ensuite, les colonnes choisies sont sélectionnées (`columns_to_show`). Si `columns_to_show` n'est pas inclus, toutes les clauses non groupby seront incluses.\n","3. Enfin, une ou plusieurs fonctions sont appliquées aux groupes obtenus par colonnes sélectionnées.\n","\n","Voici un exemple où nous regroupons les données en fonction des valeurs de la variable `Churn` et affichons les statistiques de trois colonnes dans chaque groupe :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"101INJisacpc"},"outputs":[],"source":["columns_to_show = ['Total day minutes', \n","                   'Total eve minutes', \n","                   'Total night minutes']\n","\n","df.groupby(['Churn'])[columns_to_show].describe(percentiles=[])"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"2NRPkPYXacpc"},"source":["Faisons la même chose, mais légèrement différemment, en passant une liste de fonctions à `agg ()` (agrégateur) :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wCs6sJndacpc"},"outputs":[],"source":["columns_to_show = ['Total day minutes', \n","                   'Total eve minutes', \n","                   'Total night minutes']\n","\n","df.groupby(['Churn'])[columns_to_show].agg([np.mean, np.std, np.min, np.max])"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"fnYbyXgSacpd"},"source":["### Tableaux récapitulatifs\n","\n","Supposons que nous voulions voir comment les observations de notre ensemble de données sont réparties dans le contexte de deux variables - `Churn` et`International plan`. Pour ce faire, nous pouvons construire un **tableau de contingence** en utilisant la méthode `crosstab`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m-UwVZJXacpd"},"outputs":[],"source":["pd.crosstab(df['Churn'], df['International plan'])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"gXqWzjFeacpd"},"outputs":[],"source":["pd.crosstab(df['Churn'], df['Voice mail plan'], normalize=True)"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"BIS2mNM5acpe"},"source":["Nous pouvons constater que la plupart des utilisateurs sont fidèles et n'utilisent pas de services supplémentaires (International Plan/Voice mail).\n","\n","Cela ressemblera aux **tableaux croisés dynamiques** pour ceux qui connaissent Excel. Et, bien sûr, les tableaux croisés dynamiques sont implémentés dans Pandas: la méthode `pivot_table` prend les paramètres suivants:\n","\n","* `values` - une liste de variables pour calculer des statistiques,  \n","* `index` - une liste de variables pour regrouper les données,\n","* `aggfunc` - quelles statistiques nous devons calculer pour les groupes, ex. somme, moyenne, maximum, minimum ou autre chose.\n","\n","Examinons le nombre moyen d'appels de jour, de soir et de nuit par code régional (area code):"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"tmY6pws1acpe"},"outputs":[],"source":["df.pivot_table(['Total day calls', 'Total eve calls', 'Total night calls'],\n","               ['Area code'], aggfunc='mean')"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"8CeuoC0Sacpe"},"source":["### Opérations de transformations d'un DataFrame\n","\n","Comme beaucoup d'autres choses avec Pandas, l'ajout de colonnes à un DataFrame est réalisable de plusieurs manières.\n","\n","Par exemple, si nous voulons calculer le nombre total d'appels pour tous les utilisateurs, créons la série `total_calls` et collons-la dans le DataFrame:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-09-15T20:59:31.059899Z","start_time":"2019-09-15T20:59:30.883127Z"},"id":"d4Exa2Z9acpf"},"outputs":[],"source":["total_calls = df['Total day calls'] + df['Total eve calls'] + \\\n","              df['Total night calls'] + df['Total intl calls']\n","df.insert(loc=len(df.columns), column='Total calls', value=total_calls) \n","# le paramètre loc est le nombre de colonnes après lequel l'objet Série doit être inséré\n","# nous l'initialisons à len(df.columns) pour le coller à la toute fin du dataframe\n","df.head()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"jKXk0ySoacpf"},"source":["Il est possible d’ajouter une colonne plus facilement sans créer d’instance Series intermédiaire:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWqxr4GXacpf"},"outputs":[],"source":["df['Total charge'] = df['Total day charge'] + df['Total eve charge'] + \\\n","                     df['Total night charge'] + df['Total intl charge']\n","df.head()"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"egitufTGacpf"},"source":["Pour supprimer des colonnes ou des lignes, utilisez la méthode `drop`, en passant les index requis et le paramètre` axis` (`1` si vous supprimez des colonnes et rien ou` 0` si vous supprimez des lignes). L'argument `inplace` indique s'il faut modifier le DataFrame d'origine. Avec `inplace = False`, la méthode` drop` ne modifie pas le DataFrame existant et en renvoie un nouveau avec des lignes ou des colonnes supprimées. Avec `inplace = True`, il modifie le DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfD5TrwIacpg"},"outputs":[],"source":["# supprimer les colonnes qui viennent d'être créées\n","df.drop(['Total charge', 'Total calls'], axis=1, inplace=True) \n","# et voici comment supprimer des lignes\n","df.drop([1, 2]).head() "]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"R3mf3PP6acpg"},"source":["## 2. Prévision du churn (taux d'attrition)\n","\n","Voyons comment le taux de désabonnement est lié à la caractéristique ou variable *International plan*. Pour ce faire, nous utiliserons un tableau de contingence `` crosstab`` et également une analyse visuelle avec `Seaborn` (`sns`)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OksCteLdacpg"},"outputs":[],"source":["pd.crosstab(df['Churn'], df['International plan'], margins=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuNyWFmlacpg"},"outputs":[],"source":["sns.countplot(x='International plan', hue='Churn', data=df);"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"hfGvzc70acph"},"source":["Nous voyons qu'avec *International Plan*, le taux de désabonnement est beaucoup plus élevé, ce qui est une observation intéressante! Peut-être des dépenses importantes et mal contrôlées avec des appels internationaux sont-elles très sujettes aux conflits et suscitent l’insatisfaction des clients de l’opérateur de télécommunications.\n","\n","Voyons ensuite une autre fonctionnalité importante - *Customer service calls*. Faisons également un tableau de synthèse et une image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wi4FfwRqacph"},"outputs":[],"source":["pd.crosstab(df['Churn'], df['Customer service calls'], margins=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7V1mJZoacph"},"outputs":[],"source":["sns.countplot(x='Customer service calls', hue='Churn', data=df);"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"usZQ7cI4acph"},"source":["Bien que ce ne soit pas évident dans le tableau récapitulatif, il ressort clairement du graphique ci-dessus que le taux de résiliation augmente fortement à partir de 4 appels de service après-vente.\n","\n","Ajoutons maintenant une variable binaire à notre DataFrame - `Customer service calls > 3` (Appels du service client> 3). Et encore une fois, voyons comment cela se rapporte au désabonnement."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6698PHRacpi"},"outputs":[],"source":["df['Many_service_calls'] = (df['Customer service calls'] > 3).astype('int')\n","\n","pd.crosstab(df['Many_service_calls'], df['Churn'], margins=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hKlJm35jacpi"},"outputs":[],"source":["sns.countplot(x='Many_service_calls', hue='Churn', data=df);"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"6uYJoc5vacpi"},"source":["Construisons une autre table de contingence qui relie *Churn* à la fois à *International plan* et à la variable nouvellement créée *Many_service_calls*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rnxKKY8_acpi"},"outputs":[],"source":["pd.crosstab(df['Many_service_calls'] & df['International plan'] , df['Churn'])"]},{"cell_type":"markdown","metadata":{"lang":"fr","id":"Zoa8hFqnacpi"},"source":["Par conséquent, si un nombre d'appels vers le centre de services est supérieur à 3 et que le *International Plan* est ajouté (et en prédisant Churn=0 sinon), on peut s’attendre à une précision de 85,8%. Ce nombre, 85,8%, que nous avons obtenu grâce à ce raisonnement très simple constitue un bon point de départ (*référence*) pour les autres modèles d’apprentissage automatique que nous allons construire.\n","\n","Au cours de ce cours, rappelez-vous qu'avant l'avènement de l'apprentissage automatique, le processus d'analyse des données ressemblait à ce que nous venons de réaliser. Récapitulatif :\n","    \n","- La part des clients fidèles dans l'ensemble de données est de 85,5%. Le modèle le plus \"simple\" qui prédit toujours un \"client fidèle\" sur de telles données devinera juste dans environ 85,5% des cas. C'est-à-dire que la proportion de réponses correctes (*précision*) des modèles suivants ne devrait pas être inférieure à ce nombre et qu'elle devrait être nettement supérieure;\n","- A l’aide d’une simple prévision pouvant être exprimée par la formule suivante: `International plan = True & Customer Service calls > 3 => Churn = 1, else Churn = 0`, on peut s’attendre à un taux de prédiction de 85,8%, qui est juste au-dessus de 85,5%. Ensuite, nous parlerons des arbres de décision et découvrirons comment trouver de telles règles **automatiquement** uniquement sur la base des données d’entrée;\n","- Nous avons obtenu ces deux bases sans appliquer l’apprentissage automatique et elles serviront de point de départ pour nos modèles ultérieurs. S'il s'avère qu'avec un effort énorme, nous n'augmentons la précision que de 0,5%, alors nous avons peut-être commis une erreur, et il suffit de nous en tenir à un simple modèle \"if-else\" avec deux conditions;\n","- Avant de former des modèles complexes, il est recommandé de mélanger un peu les données, de tracer des graphiques et de vérifier des hypothèses simples. De plus, dans les applications métier de l'apprentissage automatique, on commence généralement par des solutions simples, pour ensuite expérimenter des solutions plus complexes."]},{"cell_type":"markdown","metadata":{"id":"JhN9upSOacpj"},"source":["## 3. Plus d'analyse visuelle"]},{"cell_type":"markdown","metadata":{"id":"cA8D8huvacpj"},"source":["### Histogrammes et diagrammes de densité\n","\n","La façon la plus simple d'examiner la distribution d'une variable numérique est de tracer son *histogramme* à l'aide de la méthode de `DataFrame` [`hist()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.hist.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jvM7hKyMacpj"},"outputs":[],"source":["features = ['Total day minutes', 'Total intl calls']\n","df[features].hist(figsize=(10, 4));"]},{"cell_type":"markdown","metadata":{"id":"4NT3-au3acpj"},"source":["Il existe également un autre moyen, souvent plus clair, de saisir la distribution: *diagrammes de densité* ou, plus officiellement, *diagrammes de densité de noyau*. Ils peuvent être considérés comme une version [lissée](https://en.wikipedia.org/wiki/Kernel_smoother) de l'histogramme. Leur principal avantage sur ces derniers est qu'ils ne dépendent pas de la taille des \"_bins_\". Créons des tracés de densité pour les deux mêmes variables:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIojZhjtacpk"},"outputs":[],"source":["df[features].plot(kind='density', subplots=True, layout=(1, 2), \n","                  sharex=False, figsize=(10, 4));"]},{"cell_type":"markdown","metadata":{"id":"WgAhkq-Vacpk"},"source":["Il est également possible de tracer une distribution des observations avec la méthode [`distplot()`](https://seaborn.pydata.org/generated/seaborn.distplot.html) de de `seaborn`. Par exemple, regardons la distribution de `Total day minutes`. Par défaut, le tracé affiche à la fois l'histogramme avec [l'estimation de la densité du noyau](https://en.wikipedia.org/wiki/Kernel_estimation_de_la_densité_) (KDE) en haut."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3o-9KJXJacpk"},"outputs":[],"source":["sns.distplot(df['Total day minutes']);"]},{"cell_type":"markdown","metadata":{"id":"HM0aIUGpacpk"},"source":["### Box plot (Boîte à moustaches)\n","\n","Un autre type de visualisation utile est un *box plot*. `seaborn` fait un excellent travail ici:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZokxbyUacpl"},"outputs":[],"source":["sns.boxplot(x='Total intl calls', data=df);"]},{"cell_type":"markdown","metadata":{"id":"iIzDA2G2acpl"},"source":["### Graphique en barres (Bar plot)\n","\n","Le diagramme à barres est une représentation graphique de la table des fréquences. La façon la plus simple de le créer est d'utiliser la fonction de `seaborn`[`countplot()`](https://seaborn.pydata.org/generated/seaborn.countplot.html). Il existe une autre fonction dans «seaborn» qui est quelque peu confondue [`barplot()`](https://seaborn.pydata.org/generated/seaborn.barplot.html) et est principalement utilisée pour la représentation de certaines statistiques de base d'une variable numérique groupée par une caractéristique catégorielle.\n","\n","Tracons les distributions de deux variables catégorielles:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yQhDlE7acpl"},"outputs":[],"source":["_, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n","\n","sns.countplot(x='Churn', data=df, ax=axes[0]);\n","sns.countplot(x='Customer service calls', data=df, ax=axes[1]);"]},{"cell_type":"markdown","metadata":{"id":"o4DARw3Racpl"},"source":["### Matrice de corrélation\n","\n","Examinons les corrélations entre les variables numériques de notre ensemble de données. Ces informations sont importantes à connaître car il existe des algorithmes d'apprentissage automatique (par exemple, régression linéaire et logistique) qui ne gèrent pas bien les variables d'entrée hautement corrélées.\n","\n","Tout d'abord, nous utiliserons la méthode [`corr()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) sur un `DataFrame` qui calcule la corrélation entre chaque paire de caratéristiques. Ensuite, nous passons la *matrice de corrélation* résultante à [`heatmap()`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) de `seaborn`, qui rend une une matrice à code couleur pour les valeurs fournies:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OHiwiW5gacpm"},"outputs":[],"source":["## Correletion map avancé\n","def plot_correlation_map(df):\n","    corr = df.corr()\n","    _ , ax = plt.subplots(figsize =(24,20))\n","    cmap = sns.diverging_palette(220,10, as_cmap = True )\n","    _ = sns.heatmap(\n","        corr, \n","        cmap = cmap,\n","        square=True, \n","        cbar_kws={'shrink' : .9}, \n","        ax=ax, \n","        annot = True, \n","        annot_kws = {'fontsize' : 12}\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_EQ0YTW0acpm"},"outputs":[],"source":["corr_matrix = df.drop(['State', 'International plan', 'Voice mail plan',\n","                      'Area code'], axis=1).corr()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yvrrx6QPacpm"},"outputs":[],"source":["plot_correlation_map(corr_matrix)"]},{"cell_type":"markdown","metadata":{"id":"28FIJn22acpm"},"source":["À partir de la matrice de corrélation colorée générée ci-dessus, nous pouvons voir qu'il y a 4 variables telles que *Total day charge* qui ont été calculées directement à partir du nombre de minutes passées sur les appels téléphoniques (*Total day minutes*). Celles-ci sont appelées variables *dépendantes* et peuvent donc être omises car elles ne fournissent aucune information supplémentaire. "]},{"cell_type":"markdown","metadata":{"id":"B9vKqjc-acpn"},"source":["### Nuage de points / Diagramme de dispersion (Scatter plot)\n","\n","Le *nuage de points* affiche les valeurs de deux variables numériques en tant que *coordonnées cartésiennes* dans l'espace 2D. Des diagrammes de dispersion en 3D sont également possibles.\n","\n","Essayons la fonction [`scatter()`](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.scatter.html) de la bibliothèque `matplotlib`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLiU9IyMacpn"},"outputs":[],"source":["plt.scatter(df['Total day minutes'], df['Total night minutes']);"]},{"cell_type":"markdown","metadata":{"id":"Kt_Dod7wacpn"},"source":["Nous obtenons une image sans intérêt de deux variables normalement distribuées. De plus, il semble que ces caractéristiques ne soient pas corrélées car la forme semblable à une ellipse est alignée avec les axes.\n","\n","Il existe une option légèrement plus sophistiquée pour créer un nuage de points avec la bibliothèque `seaborn`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMVMuXdpacpn"},"outputs":[],"source":["sns.jointplot(x='Total day minutes', y='Total night minutes', \n","              data=df, kind='scatter');"]},{"cell_type":"markdown","metadata":{"id":"Mc9N2vqeacpn"},"source":["#### Matrice de nuage de points (Scatterplot matrix)\n","\n","Dans certains cas, nous pouvons vouloir tracer une *matrice de nuage de points* telle que celle illustrée ci-dessous. Sa diagonale contient les distributions des variables correspondantes et les diagrammes de dispersion pour chaque paire de variables remplissent le reste de la matrice."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1KcX4XMsacpo"},"outputs":[],"source":["features = list(set(df.columns) - set(['State', 'International plan', 'Voice mail plan',  'Area code',\n","                                      'Total day charge',   'Total eve charge',   'Total night charge',\n","                                        'Total intl charge', 'Churn']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_CjnSnBUacpo"},"outputs":[],"source":["# `pairplot()` may become very slow with the SVG format\n","%config InlineBackend.figure_format = 'png'\n","sns.pairplot(df[features]);"]},{"cell_type":"markdown","metadata":{"id":"SGDFAbJVacpo"},"source":["De plus, les points peuvent être codés par couleur ou par taille afin que les valeurs d'une troisième variable catégorielle soient également présentées dans la même figure. On utilise le paramètre «hue» pour indiquer notre caractéristique d'intérêt:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQmAGO_zacpo"},"outputs":[],"source":["sns.pairplot(df[features + ['Churn']], hue='Churn')"]}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"nbTranslate":{"displayLangs":["*"],"hotkey":"alt-t","langInMainMenu":true,"sourceLang":"en","targetLang":"fr","useGoogleTranslate":true},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":false,"skip_h1_title":true,"title_cell":"Sommaire de l'article","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"427px","left":"65px","top":"180px","width":"260px"},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"TD_1_Classification des données.ipynb","provenance":[],"collapsed_sections":["nLEz1dIIacpR","Q9wyFnI_acpS","ShuL9XnbacpY","NYV4YX5hacpb","fnYbyXgSacpd","8CeuoC0Sacpe","cA8D8huvacpj","HM0aIUGpacpk","iIzDA2G2acpl"]}},"nbformat":4,"nbformat_minor":0}